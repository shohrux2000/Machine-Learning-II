{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d01a84d",
   "metadata": {},
   "source": [
    "\n",
    "# Classification Task — Predicting Tax Avoidance Categories\n",
    "**ML2 Course — Extra Points Assignment**  \n",
    "**Primary metric: Macro F1-Score**\n",
    "\n",
    "> Complete this notebook and push to GitHub. Save the best model(s) in `models/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf056fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Imports & Config ===\n",
    "import os, warnings, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16b6e3",
   "metadata": {},
   "source": [
    "## Part 1 — Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de636fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load prepared datasets\n",
    "train_path = os.path.join(DATA_DIR, \"train_fe.csv\")\n",
    "test_path  = os.path.join(DATA_DIR, \"test_fe.csv\")\n",
    "\n",
    "assert os.path.exists(train_path), f\"Missing file: {train_path}. Put train_fe.csv in data/\"\n",
    "assert os.path.exists(test_path),  f\"Missing file: {test_path}. Put test_fe.csv in data/\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test  = pd.read_csv(test_path)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create target variable from ETR thresholds\n",
    "def label_from_etr(etr):\n",
    "    if etr > 0.25:\n",
    "        return 0  # Low Tax Avoidance\n",
    "    elif etr > 0.15:\n",
    "        return 1  # Medium Tax Avoidance\n",
    "    else:\n",
    "        return 2  # High Tax Avoidance\n",
    "\n",
    "for df in (train, test):\n",
    "    if \"ETR\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'ETR' column in the dataset.\")\n",
    "    df[\"target\"] = df[\"ETR\"].apply(label_from_etr)\n",
    "\n",
    "train[\"target\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check class balance\n",
    "ax = train[\"target\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "ax.set_title(\"Class Distribution (train)\")\n",
    "ax.set_xlabel(\"Class (0=Low, 1=Medium, 2=High)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select features — use the engineered features from the project except obvious targets/ids\n",
    "drop_cols = [\"ETR\", \"target\"]\n",
    "id_like = [c for c in train.columns if c.lower() in {\"id\", \"date\", \"firm\", \"ticker\"}]\n",
    "drop_cols.extend(id_like)\n",
    "drop_cols = list(set(drop_cols))\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in drop_cols]\n",
    "print(f\"{len(feature_cols)} features:\")\n",
    "print(feature_cols[:20], \"...\" if len(feature_cols) > 20 else \"\")\n",
    "\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[\"target\"].copy()\n",
    "\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[\"target\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ac5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time-series aware CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Grids\n",
    "logreg_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\", \"newton-cg\", \"saga\"],\n",
    "    \"clf__max_iter\": [2000]\n",
    "}\n",
    "\n",
    "knn_grid = {\n",
    "    \"clf__n_neighbors\": [3,5,9,15],\n",
    "    \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "    \"clf__p\": [1,2]\n",
    "}\n",
    "\n",
    "svc_grid = {\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__kernel\": [\"rbf\", \"linear\"],\n",
    "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff24a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune_and_score(name, estimator, param_grid, X, y, cv, scoring=\"f1_macro\"):\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False) if hasattr(X, \"sparse\") else StandardScaler()),\n",
    "        (\"clf\", estimator)\n",
    "    ])\n",
    "    gs = GridSearchCV(pipe, param_grid, cv=cv, scoring=scoring, n_jobs=-1, refit=True, verbose=0)\n",
    "    gs.fit(X, y)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Best params:\", gs.best_params_)\n",
    "    print(f\"CV best {scoring}: {gs.best_score_:.4f}\")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"search\": gs,\n",
    "        \"best_score\": gs.best_score_,\n",
    "        \"best_estimator\": gs.best_estimator_\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0a759",
   "metadata": {},
   "source": [
    "## Part 2 — Model Training & Validation (TimeSeriesSplit + GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336440be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "results.append(tune_and_score(\"LogisticRegression\", LogisticRegression(multi_class=\"auto\"), logreg_grid, X_train, y_train, tscv))\n",
    "results.append(tune_and_score(\"KNN\", KNeighborsClassifier(), knn_grid, X_train, y_train, tscv))\n",
    "results.append(tune_and_score(\"SVC\", SVC(probability=False), svc_grid, X_train, y_train, tscv))\n",
    "\n",
    "# Compare\n",
    "summary = pd.DataFrame({\n",
    "    \"Model\": [r[\"name\"] for r in results],\n",
    "    \"CV_MacroF1\": [r[\"best_score\"] for r in results]\n",
    "}).sort_values(\"CV_MacroF1\", ascending=False).reset_index(drop=True)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fb505",
   "metadata": {},
   "source": [
    "## Part 3 — Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best = max(results, key=lambda r: r[\"best_score\"])\n",
    "best_name = best[\"name\"]\n",
    "best_est = best[\"best_estimator\"]\n",
    "print(\"Selected best model:\", best_name)\n",
    "\n",
    "# Fit on full TRAIN\n",
    "best_est.fit(X_train, y_train)\n",
    "\n",
    "# Predict on TEST\n",
    "y_pred = best_est.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test Macro F1: {macro_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Classification report (per class):\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1,2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2])\n",
    "disp.plot(values_format='d')\n",
    "plt.title(f\"Confusion Matrix — {best_name}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save best model and (optionally) scaler inside the Pipeline\n",
    "best_model_path = os.path.join(MODEL_DIR, \"best_model.pkl\")\n",
    "joblib.dump(best_est, best_model_path)\n",
    "print(\"Saved:\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c0857",
   "metadata": {},
   "source": [
    "\n",
    "### Brief Interpretation\n",
    "- We selected the model with the highest **CV Macro F1** using **TimeSeriesSplit** to respect time ordering.  \n",
    "- Final test results report **macro F1**, accuracy, and the confusion matrix for classes 0/1/2.  \n",
    "- If confusion shows frequent confusion between classes 1 and 2, consider adding class weights, different ETR thresholds, or additional features.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
